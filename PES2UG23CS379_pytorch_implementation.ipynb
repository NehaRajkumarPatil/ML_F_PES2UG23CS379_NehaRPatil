{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lpdHqXWOxxpg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d197df6-0732-4975-a9be-89941df17e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Selected Framework: PYTORCH\n",
            "   Using PyTorch tensors for data processing\n",
            "STARTING MULTI-DATASET EVALUATION\n",
            "Framework: PYTORCH\n",
            "Datasets to test: 3\n",
            "\n",
            " Processing dataset 1/3: Mushrooms\n",
            "\n",
            "================================================================================\n",
            " TESTING DATASET: MUSHROOMS\n",
            " File: mushrooms.csv\n",
            " Framework: PYTORCH\n",
            "================================================================================\n",
            " Target column: 'class' (last column)\n",
            "Original dataset info:\n",
            "Shape: (8124, 23)\n",
            "Columns: ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat', 'class']\n",
            "\n",
            "First few rows:\n",
            "\n",
            "cap-shape: ['x' 'b' 's' 'f' 'k'] -> [5 0 4 2 3]\n",
            "\n",
            "cap-surface: ['s' 'y' 'f' 'g'] -> [2 3 0 1]\n",
            "\n",
            "cap-color: ['n' 'y' 'w' 'g' 'e'] -> [4 9 8 3 2]\n",
            "\n",
            "class: ['p' 'e'] -> [1 0]\n",
            "\n",
            " DATASET SUMMARY\n",
            "========================================\n",
            "Processed dataset shape: torch.Size([8124, 23])\n",
            "Number of features: 22\n",
            "Features: ['cap-shape', 'cap-surface', 'cap-color']...\n",
            "Target: class\n",
            "Framework: PYTORCH\n",
            "Data type: <class 'torch.Tensor'>\n",
            "Number of classes: 2\n",
            "Class distribution: {0: 4208, 1: 3916}\n",
            "\n",
            " DECISION TREE CONSTRUCTION\n",
            "========================================\n",
            "Total samples: 8124\n",
            "Training samples: 6499\n",
            "Testing samples: 1625\n",
            "\n",
            " Constructing decision tree using training data...\n",
            "\n",
            " Decision tree construction completed!\n",
            "\n",
            " OVERALL PERFORMANCE METRICS\n",
            "========================================\n",
            "Accuracy:             1.0000 (100.00%)\n",
            "Precision (weighted): 1.0000\n",
            "Recall (weighted):    1.0000\n",
            "F1-Score (weighted):  1.0000\n",
            "Precision (macro):    1.0000\n",
            "Recall (macro):       1.0000\n",
            "F1-Score (macro):     1.0000\n",
            "\n",
            " TREE COMPLEXITY METRICS\n",
            "========================================\n",
            "Maximum Depth:        4\n",
            "Total Nodes:          29\n",
            "Leaf Nodes:           24\n",
            "Internal Nodes:       5\n",
            "\n",
            " Processing dataset 2/3: Tic-Tac-Toe\n",
            "\n",
            "================================================================================\n",
            " TESTING DATASET: TIC-TAC-TOE\n",
            " File: tictactoe.csv\n",
            " Framework: PYTORCH\n",
            "================================================================================\n",
            " Target column: 'Class' (last column)\n",
            "Original dataset info:\n",
            "Shape: (958, 10)\n",
            "Columns: ['top-left-square', 'top-middle-square', 'top-right-square', 'middle-left-square', 'middle-middle-square', 'middle-right-square', 'bottom-left-square', 'bottom-middle-square', 'bottom-right-square', 'Class']\n",
            "\n",
            "First few rows:\n",
            "\n",
            "top-left-square: ['x' 'o' 'b'] -> [2 1 0]\n",
            "\n",
            "top-middle-square: ['x' 'o' 'b'] -> [2 1 0]\n",
            "\n",
            "top-right-square: ['x' 'o' 'b'] -> [2 1 0]\n",
            "\n",
            "Class: ['positive' 'negative'] -> [1 0]\n",
            "\n",
            " DATASET SUMMARY\n",
            "========================================\n",
            "Processed dataset shape: torch.Size([958, 10])\n",
            "Number of features: 9\n",
            "Features: ['top-left-square', 'top-middle-square', 'top-right-square']...\n",
            "Target: Class\n",
            "Framework: PYTORCH\n",
            "Data type: <class 'torch.Tensor'>\n",
            "Number of classes: 2\n",
            "Class distribution: {0: 332, 1: 626}\n",
            "\n",
            " DECISION TREE CONSTRUCTION\n",
            "========================================\n",
            "Total samples: 958\n",
            "Training samples: 766\n",
            "Testing samples: 192\n",
            "\n",
            " Constructing decision tree using training data...\n",
            "\n",
            " Decision tree construction completed!\n",
            "\n",
            " OVERALL PERFORMANCE METRICS\n",
            "========================================\n",
            "Accuracy:             0.8594 (85.94%)\n",
            "Precision (weighted): 0.8599\n",
            "Recall (weighted):    0.8594\n",
            "F1-Score (weighted):  0.8596\n",
            "Precision (macro):    0.8435\n",
            "Recall (macro):       0.8460\n",
            "F1-Score (macro):     0.8447\n",
            "\n",
            " TREE COMPLEXITY METRICS\n",
            "========================================\n",
            "Maximum Depth:        5\n",
            "Total Nodes:          155\n",
            "Leaf Nodes:           103\n",
            "Internal Nodes:       52\n",
            "\n",
            " Processing dataset 3/3: Nursery\n",
            "\n",
            "================================================================================\n",
            " TESTING DATASET: NURSERY\n",
            " File: Nursery.csv\n",
            " Framework: PYTORCH\n",
            "================================================================================\n",
            " Target column: 'class' (last column)\n",
            "Original dataset info:\n",
            "Shape: (12960, 9)\n",
            "Columns: ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health', 'class']\n",
            "\n",
            "First few rows:\n",
            "\n",
            "parents: ['usual' 'pretentious' 'great_pret'] -> [2 1 0]\n",
            "\n",
            "has_nurs: ['proper' 'less_proper' 'improper' 'critical' 'very_crit'] -> [3 2 1 0 4]\n",
            "\n",
            "form: ['complete' 'completed' 'incomplete' 'foster'] -> [0 1 3 2]\n",
            "\n",
            "class: ['recommend' 'priority' 'not_recom' 'very_recom' 'spec_prior'] -> [2 1 0 4 3]\n",
            "\n",
            " DATASET SUMMARY\n",
            "========================================\n",
            "Processed dataset shape: torch.Size([12960, 9])\n",
            "Number of features: 8\n",
            "Features: ['parents', 'has_nurs', 'form']...\n",
            "Target: class\n",
            "Framework: PYTORCH\n",
            "Data type: <class 'torch.Tensor'>\n",
            "Number of classes: 5\n",
            "Class distribution: {0: 4320, 1: 4266, 2: 2, 3: 4044, 4: 328}\n",
            "\n",
            " DECISION TREE CONSTRUCTION\n",
            "========================================\n",
            "Total samples: 12960\n",
            "Training samples: 10368\n",
            "Testing samples: 2592\n",
            "\n",
            " Constructing decision tree using training data...\n",
            "\n",
            " Decision tree construction completed!\n",
            "\n",
            " OVERALL PERFORMANCE METRICS\n",
            "========================================\n",
            "Accuracy:             0.9394 (93.94%)\n",
            "Precision (weighted): 0.9396\n",
            "Recall (weighted):    0.9394\n",
            "F1-Score (weighted):  0.9392\n",
            "Precision (macro):    0.6871\n",
            "Recall (macro):       0.6914\n",
            "F1-Score (macro):     0.6890\n",
            "\n",
            " TREE COMPLEXITY METRICS\n",
            "========================================\n",
            "Maximum Depth:        5\n",
            "Total Nodes:          267\n",
            "Leaf Nodes:           186\n",
            "Internal Nodes:       81\n",
            "\n",
            "====================================================================================================\n",
            " COMPREHENSIVE SUMMARY REPORT - PYTORCH FRAMEWORK\n",
            "====================================================================================================\n",
            "\n",
            " SUCCESSFUL EVALUATIONS: 3/3\n",
            "================================================================================\n",
            "Dataset         Accuracy   Precision  Recall     F1-Score   Tree Depth   Nodes   \n",
            "--------------------------------------------------------------------------------\n",
            "Mushrooms       1.0000     1.0000     1.0000     1.0000     4            29      \n",
            "Tic-Tac-Toe     0.8594     0.8599     0.8594     0.8596     5            155     \n",
            "Nursery         0.9394     0.9396     0.9394     0.9392     5            267     \n",
            "\n",
            " BEST PERFORMER (Accuracy): Mushrooms (1.0000)\n",
            "\n",
            " DATASET COMPLEXITY ANALYSIS\n",
            "==================================================\n",
            "\n",
            "Mushrooms:\n",
            "  • Dataset size: 8,124 samples, 22 features\n",
            "  • Classes: 2 ([0, 1])\n",
            "  • Tree complexity: 4 depth, 29 nodes\n",
            "  • Performance: 100.0% accuracy\n",
            "\n",
            "Tic-Tac-Toe:\n",
            "  • Dataset size: 958 samples, 9 features\n",
            "  • Classes: 2 ([0, 1])\n",
            "  • Tree complexity: 5 depth, 155 nodes\n",
            "  • Performance: 85.9% accuracy\n",
            "\n",
            "Nursery:\n",
            "  • Dataset size: 12,960 samples, 8 features\n",
            "  • Classes: 5 ([0, 1, 2, 3, 4])\n",
            "  • Tree complexity: 5 depth, 267 nodes\n",
            "  • Performance: 93.9% accuracy\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            " EVALUATION COMPLETE!\n",
            "Framework used: PYTORCH\n",
            "Total datasets processed: 3\n",
            "Successful evaluations: 3\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import importlib\n",
        "import argparse\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define default values for the arguments instead of using argparse\n",
        "subname = \"EC_F_PES2UG23CS379_Lab3\"  # Replace with your actual module name\n",
        "datasets = [\n",
        "    {\"name\": \"Mushrooms\", \"path\": \"mushrooms.csv\"},\n",
        "    {\"name\": \"Tic-Tac-Toe\", \"path\": \"tictactoe.csv\"},\n",
        "    {\"name\": \"Nursery\", \"path\": \"Nursery.csv\"}\n",
        "]\n",
        "\n",
        "# CHOOSE YOUR FRAMEWORK HERE:\n",
        "framework = 'pytorch'  # Change to 'sklearn' for NumPy/sklearn framework\n",
        "# framework = 'sklearn'  # Uncomment this line to use NumPy instead\n",
        "\n",
        "print_tree_flag = False\n",
        "print_construction_flag = False\n",
        "\n",
        "print(f\" Selected Framework: {framework.upper()}\")\n",
        "if framework == 'pytorch':\n",
        "    print(\"   Using PyTorch tensors for data processing\")\n",
        "else:\n",
        "    print(\"   Using NumPy arrays for data processing\")\n",
        "\n",
        "try:\n",
        "    mymodule = importlib.import_module(subname)\n",
        "except Exception as e:\n",
        "    print(f\"Error importing module '{subname}': {e}\")\n",
        "    print(\"Please ensure your module is named correctly and is in the Colab environment.\")\n",
        "    sys.exit()\n",
        "\n",
        "# Assuming these functions are defined in your imported module\n",
        "try:\n",
        "    get_selected_attribute = mymodule.get_selected_attribute\n",
        "    get_information_gain = mymodule.get_information_gain\n",
        "    get_avg_info_of_attribute = mymodule.get_avg_info_of_attribute\n",
        "    get_entropy_of_dataset = mymodule.get_entropy_of_dataset\n",
        "except AttributeError as e:\n",
        "    print(f\"Error: Missing required function in module '{subname}': {e}\")\n",
        "    print(\"Please ensure your module contains the functions: get_selected_attribute, get_information_gain, get_avg_info_of_attribute, get_entropy_of_dataset\")\n",
        "    sys.exit()\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    if len(y_true) != len(y_pred):\n",
        "        raise ValueError(\"y_true and y_pred must have the same length\")\n",
        "\n",
        "    if isinstance(y_true, torch.Tensor):\n",
        "        y_true = y_true.numpy()\n",
        "    if isinstance(y_pred, torch.Tensor):\n",
        "        y_pred = y_pred.numpy()\n",
        "\n",
        "    valid_mask = np.array([pred is not None for pred in y_pred])\n",
        "    if not np.any(valid_mask):\n",
        "        return 0.0\n",
        "\n",
        "    y_true_valid = y_true[valid_mask]\n",
        "    y_pred_valid = np.array(y_pred)[valid_mask]\n",
        "\n",
        "    correct = np.sum(y_true_valid == y_pred_valid)\n",
        "    total = len(y_true_valid)\n",
        "\n",
        "    return correct / total if total > 0 else 0.0\n",
        "\n",
        "def calculate_precision_recall_f1(y_true, y_pred, average='weighted'):\n",
        "    if len(y_true) != len(y_pred):\n",
        "        raise ValueError(\"y_true and y_pred must have the same length\")\n",
        "\n",
        "    if isinstance(y_true, torch.Tensor):\n",
        "        y_true = y_true.numpy()\n",
        "    if isinstance(y_pred, torch.Tensor):\n",
        "        y_pred = y_pred.numpy()\n",
        "\n",
        "    valid_mask = np.array([pred is not None for pred in y_pred])\n",
        "    if not np.any(valid_mask):\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    y_true_valid = y_true[valid_mask]\n",
        "    y_pred_valid = np.array(y_pred)[valid_mask]\n",
        "\n",
        "    classes = np.unique(np.concatenate([y_true_valid, y_pred_valid]))\n",
        "\n",
        "    if average == 'weighted':\n",
        "        precisions, recalls, f1s, supports = [], [], [], []\n",
        "\n",
        "        for cls in classes:\n",
        "            tp = np.sum((y_true_valid == cls) & (y_pred_valid == cls))\n",
        "            fp = np.sum((y_true_valid != cls) & (y_pred_valid == cls))\n",
        "            fn = np.sum((y_true_valid == cls) & (y_pred_valid != cls))\n",
        "\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "            support = np.sum(y_true_valid == cls)\n",
        "\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            f1s.append(f1)\n",
        "            supports.append(support)\n",
        "\n",
        "        total_support = sum(supports)\n",
        "        if total_support == 0:\n",
        "            return 0.0, 0.0, 0.0\n",
        "\n",
        "        weighted_precision = sum(p * s for p, s in zip(precisions, supports)) / total_support\n",
        "        weighted_recall = sum(r * s for r, s in zip(recalls, supports)) / total_support\n",
        "        weighted_f1 = sum(f * s for f, s in zip(f1s, supports)) / total_support\n",
        "\n",
        "        return weighted_precision, weighted_recall, weighted_f1\n",
        "\n",
        "    elif average == 'macro':\n",
        "        precisions, recalls, f1s = [], [], []\n",
        "\n",
        "        for cls in classes:\n",
        "            tp = np.sum((y_true_valid == cls) & (y_pred_valid == cls))\n",
        "            fp = np.sum((y_true_valid != cls) & (y_pred_valid == cls))\n",
        "            fn = np.sum((y_true_valid == cls) & (y_pred_valid != cls))\n",
        "\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "            f1s.append(f1)\n",
        "\n",
        "        return np.mean(precisions), np.mean(recalls), np.mean(f1s)\n",
        "\n",
        "def calculate_per_class_metrics(y_true, y_pred):\n",
        "    if len(y_true) != len(y_pred):\n",
        "        raise ValueError(\"y_true and y_pred must have the same length\")\n",
        "\n",
        "    if isinstance(y_true, torch.Tensor):\n",
        "        y_true = y_true.numpy()\n",
        "    if isinstance(y_pred, torch.Tensor):\n",
        "        y_pred = y_pred.numpy()\n",
        "\n",
        "    valid_mask = np.array([pred is not None for pred in y_pred])\n",
        "    if not np.any(valid_mask):\n",
        "        return {}\n",
        "\n",
        "    y_true_valid = y_true[valid_mask]\n",
        "    y_pred_valid = np.array(y_pred)[valid_mask]\n",
        "\n",
        "    classes = np.unique(np.concatenate([y_true_valid, y_pred_valid]))\n",
        "    metrics = {}\n",
        "\n",
        "    for cls in classes:\n",
        "        tp = np.sum((y_true_valid == cls) & (y_pred_valid == cls))\n",
        "        fp = np.sum((y_true_valid != cls) & (y_pred_valid == cls))\n",
        "        fn = np.sum((y_true_valid == cls) & (y_pred_valid != cls))\n",
        "        tn = np.sum((y_true_valid != cls) & (y_pred_valid != cls))\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        support = np.sum(y_true_valid == cls)\n",
        "\n",
        "        metrics[cls] = {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1,\n",
        "            'specificity': specificity,\n",
        "            'support': support,\n",
        "            'true_positives': tp,\n",
        "            'false_positives': fp,\n",
        "            'false_negatives': fn,\n",
        "            'true_negatives': tn\n",
        "        }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def calculate_tree_complexity_metrics(tree):\n",
        "    if isinstance(tree, int) or tree is None:\n",
        "        return {\n",
        "            'max_depth': 0,\n",
        "            'num_nodes': 1,\n",
        "            'num_leaves': 1,\n",
        "            'num_internal_nodes': 0\n",
        "        }\n",
        "\n",
        "    if not isinstance(tree, dict):\n",
        "        return {\n",
        "            'max_depth': 0,\n",
        "            'num_nodes': 1,\n",
        "            'num_leaves': 1,\n",
        "            'num_internal_nodes': 0\n",
        "        }\n",
        "\n",
        "    def get_tree_stats(node, depth=0):\n",
        "        if isinstance(node, int) or node is None:\n",
        "            return {\n",
        "                'max_depth': depth,\n",
        "                'num_nodes': 1,\n",
        "                'num_leaves': 1,\n",
        "                'num_internal_nodes': 0\n",
        "            }\n",
        "\n",
        "        if not isinstance(node, dict) or 'branches' not in node:\n",
        "            return {\n",
        "                'max_depth': depth,\n",
        "                'num_nodes': 1,\n",
        "                'num_leaves': 1,\n",
        "                'num_internal_nodes': 0\n",
        "            }\n",
        "\n",
        "        max_depth = depth\n",
        "        total_nodes = 1\n",
        "        total_leaves = 0\n",
        "        total_internal = 1\n",
        "\n",
        "        for branch_value, subtree in node['branches'].items():\n",
        "            subtree_stats = get_tree_stats(subtree, depth + 1)\n",
        "            max_depth = max(max_depth, subtree_stats['max_depth'])\n",
        "            total_nodes += subtree_stats['num_nodes']\n",
        "            total_leaves += subtree_stats['num_leaves']\n",
        "            total_internal += subtree_stats['num_internal_nodes']\n",
        "\n",
        "        return {\n",
        "            'max_depth': max_depth,\n",
        "            'num_nodes': total_nodes,\n",
        "            'num_leaves': total_leaves,\n",
        "            'num_internal_nodes': total_internal\n",
        "        }\n",
        "\n",
        "    return get_tree_stats(tree)\n",
        "\n",
        "def evaluate_decision_tree(tree, X_test, y_test, cols, class_names=None):\n",
        "    predictions = []\n",
        "\n",
        "    for i, sample in enumerate(X_test):\n",
        "        pred = predict_single_sample(tree, sample, cols)\n",
        "        predictions.append(pred)\n",
        "\n",
        "    accuracy = calculate_accuracy(y_test, predictions)\n",
        "    precision, recall, f1 = calculate_precision_recall_f1(y_test, predictions, average='weighted')\n",
        "    precision_macro, recall_macro, f1_macro = calculate_precision_recall_f1(y_test, predictions, average='macro')\n",
        "\n",
        "    per_class_metrics = calculate_per_class_metrics(y_test, predictions)\n",
        "    tree_stats = calculate_tree_complexity_metrics(tree)\n",
        "\n",
        "    print(f\"\\n OVERALL PERFORMANCE METRICS\")\n",
        "    print(f\"{'='*40}\")\n",
        "    print(f\"Accuracy:             {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"Precision (weighted): {precision:.4f}\")\n",
        "    print(f\"Recall (weighted):    {recall:.4f}\")\n",
        "    print(f\"F1-Score (weighted):  {f1:.4f}\")\n",
        "    print(f\"Precision (macro):    {precision_macro:.4f}\")\n",
        "    print(f\"Recall (macro):       {recall_macro:.4f}\")\n",
        "    print(f\"F1-Score (macro):     {f1_macro:.4f}\")\n",
        "\n",
        "    print(f\"\\n TREE COMPLEXITY METRICS\")\n",
        "    print(f\"{'='*40}\")\n",
        "    print(f\"Maximum Depth:        {tree_stats['max_depth']}\")\n",
        "    print(f\"Total Nodes:          {tree_stats['num_nodes']}\")\n",
        "    print(f\"Leaf Nodes:           {tree_stats['num_leaves']}\")\n",
        "    print(f\"Internal Nodes:       {tree_stats['num_internal_nodes']}\")\n",
        "\n",
        "    total_predictions = len(predictions)\n",
        "    valid_predictions = sum(1 for p in predictions if p is not None)\n",
        "    prediction_rate = valid_predictions / total_predictions if total_predictions > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision_weighted': precision,\n",
        "        'recall_weighted': recall,\n",
        "        'f1_weighted': f1,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'per_class_metrics': per_class_metrics,\n",
        "        'tree_complexity': tree_stats,\n",
        "        'predictions': predictions,\n",
        "        'prediction_rate': prediction_rate\n",
        "    }\n",
        "\n",
        "def convert_data_for_framework(data, target_framework):\n",
        "    if target_framework == 'pytorch':\n",
        "        if isinstance(data, np.ndarray):\n",
        "            return torch.tensor(data, dtype=torch.float32)\n",
        "        return data\n",
        "    else:\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            return data.numpy()\n",
        "        return data\n",
        "\n",
        "def get_unique_values(data, column_idx, target_framework):\n",
        "    if target_framework == 'pytorch':\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            return torch.unique(data[:, column_idx])\n",
        "        else:\n",
        "            tensor_data = torch.tensor(data, dtype=torch.float32)\n",
        "            return torch.unique(tensor_data[:, column_idx])\n",
        "    else:\n",
        "        if isinstance(data, np.ndarray):\n",
        "            return np.unique(data[:, column_idx])\n",
        "        else:\n",
        "            return np.unique(data.numpy()[:, column_idx])\n",
        "\n",
        "def get_unique_with_counts(data, column_idx, target_framework):\n",
        "    \"\"\"Get unique values and counts in a framework-agnostic way\"\"\"\n",
        "    if target_framework == 'pytorch':\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            return torch.unique(data[:, column_idx], return_counts=True)\n",
        "        else:\n",
        "            tensor_data = torch.tensor(data, dtype=torch.float32)\n",
        "            return torch.unique(tensor_data[:, column_idx], return_counts=True)\n",
        "    else:  # sklearn/numpy\n",
        "        if isinstance(data, np.ndarray):\n",
        "            return np.unique(data[:, column_idx], return_counts=True)\n",
        "        else:\n",
        "            return np.unique(data.numpy()[:, column_idx], return_counts=True)\n",
        "\n",
        "def create_mask(data, column_idx, value, target_framework):\n",
        "    \"\"\"Create boolean mask in a framework-agnostic way\"\"\"\n",
        "    if target_framework == 'pytorch':\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            return data[:, column_idx] == value\n",
        "        else:\n",
        "            tensor_data = torch.tensor(data, dtype=torch.float32)\n",
        "            return tensor_data[:, column_idx] == value\n",
        "    else:  # sklearn/numpy\n",
        "        if isinstance(data, np.ndarray):\n",
        "            return data[:, column_idx] == value\n",
        "        else:\n",
        "            return data.numpy()[:, column_idx] == value\n",
        "\n",
        "def get_item_value(value, target_framework):\n",
        "    \"\"\"Extract scalar value in a framework-agnostic way\"\"\"\n",
        "    if target_framework == 'pytorch':\n",
        "        if hasattr(value, 'item'):\n",
        "            return value.item()\n",
        "        return float(value)\n",
        "    else:  # sklearn/numpy\n",
        "        if isinstance(value, np.ndarray):\n",
        "            return value.item() if value.size == 1 else value\n",
        "        return float(value)\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset by encoding categorical variables\n",
        "    The last column is automatically treated as the target variable\n",
        "    \"\"\"\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    print(\"Original dataset info:\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "    print(\"\\nFirst few rows:\")\n",
        "\n",
        "    label_encoders = {}\n",
        "    for column in df_processed.columns:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[column] = le.fit_transform(df_processed[column])\n",
        "        label_encoders[column] = le\n",
        "\n",
        "        if column in list(df.columns)[:3] or column == df.columns[-1]:\n",
        "            unique_orig = df[column].unique()[:5]\n",
        "            unique_encoded = df_processed[column].unique()[:5]\n",
        "            print(f\"\\n{column}: {unique_orig} -> {unique_encoded}\")\n",
        "\n",
        "    return df_processed, label_encoders\n",
        "\n",
        "def construct_tree(data, cols, used_attributes=None, level=0, max_depth=5, target_framework='pytorch', print_construction=False):\n",
        "    \"\"\"\n",
        "    Recursively construct decision tree using ID3 algorithm\n",
        "    Assumes last column is the target variable\n",
        "    Returns: Tree structure (dict for internal nodes, int for leaf nodes)\n",
        "    \"\"\"\n",
        "    if used_attributes is None:\n",
        "        used_attributes = set()\n",
        "\n",
        "    # Base case: empty data\n",
        "    if len(data) == 0:\n",
        "        return None\n",
        "\n",
        "    # Convert data to appropriate framework format\n",
        "    framework_data = convert_data_for_framework(data, target_framework)\n",
        "\n",
        "    # Print the entropy of the current dataset\n",
        "    entropy = get_entropy_of_dataset(framework_data)\n",
        "    if print_construction:\n",
        "        print_node_info(f\"Entropy = {entropy:.4f}\", level)\n",
        "\n",
        "    # Base case: pure node (entropy = 0)\n",
        "    if entropy == 0:\n",
        "        # Get the class (all samples have same class)\n",
        "        if target_framework == 'pytorch':\n",
        "            if isinstance(data, torch.Tensor):\n",
        "                target_values = data[:, -1]\n",
        "            else:\n",
        "                target_values = torch.tensor(data)[:, -1]\n",
        "            majority_class = int(target_values[0].item())  # All same, so take first\n",
        "        else:\n",
        "            if isinstance(data, np.ndarray):\n",
        "                target_values = data[:, -1]\n",
        "            else:\n",
        "                target_values = np.array(data)[:, -1]\n",
        "            majority_class = int(target_values[0])  # All same, so take first\n",
        "\n",
        "        if print_construction:\n",
        "            print_node_info(f\"Hypothesis: Class {majority_class}\", level)\n",
        "        return majority_class\n",
        "\n",
        "    # Base case: max depth reached\n",
        "    if level >= max_depth:\n",
        "        # Get majority class\n",
        "        unique_vals, counts = get_unique_with_counts(data, -1, target_framework)\n",
        "        if target_framework == 'pytorch':\n",
        "            majority_idx = torch.argmax(counts)\n",
        "            majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "        else:\n",
        "            majority_idx = np.argmax(counts)\n",
        "            majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "\n",
        "        if print_construction:\n",
        "            print_node_info(f\"Hypothesis: Class {majority_class} (max depth reached)\", level)\n",
        "        return majority_class\n",
        "\n",
        "    # Base case: no more attributes available\n",
        "    num_features = len(cols) - 1\n",
        "    if len(used_attributes) >= num_features:\n",
        "        # Get majority class\n",
        "        unique_vals, counts = get_unique_with_counts(data, -1, target_framework)\n",
        "        if target_framework == 'pytorch':\n",
        "            majority_idx = torch.argmax(counts)\n",
        "            majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "        else:\n",
        "            majority_idx = np.argmax(counts)\n",
        "            majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "\n",
        "        if print_construction:\n",
        "            print_node_info(f\"Hypothesis: Class {majority_class} (no more attributes)\", level)\n",
        "        return majority_class\n",
        "\n",
        "    # Get the selected attribute and information gains\n",
        "    try:\n",
        "        gain_dict, selected_attribute = get_selected_attribute(framework_data)\n",
        "\n",
        "        # Filter out already used attributes\n",
        "        available_gains = {attr: gain for attr, gain in gain_dict.items()\n",
        "                          if attr not in used_attributes}\n",
        "\n",
        "        # Base case: no available attributes or no information gain\n",
        "        if not available_gains or max(available_gains.values()) <= 0:\n",
        "            unique_vals, counts = get_unique_with_counts(data, -1, target_framework)\n",
        "            if target_framework == 'pytorch':\n",
        "                majority_idx = torch.argmax(counts)\n",
        "                majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "            else:\n",
        "                majority_idx = np.argmax(counts)\n",
        "                majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "\n",
        "            if print_construction:\n",
        "                print_node_info(f\"Hypothesis: Class {majority_class} (no gain)\", level)\n",
        "            return majority_class\n",
        "\n",
        "        selected_attribute = max(available_gains, key=available_gains.get)\n",
        "\n",
        "        if print_construction:\n",
        "            print_node_info(f\"Selected Attribute: {cols[selected_attribute]} (gain: {available_gains[selected_attribute]:.4f})\", level)\n",
        "\n",
        "        tree_node = {\n",
        "            'attribute': selected_attribute,\n",
        "            'attribute_name': cols[selected_attribute],\n",
        "            'gain': available_gains[selected_attribute],\n",
        "            'level': level,\n",
        "            'branches': {}\n",
        "        }\n",
        "\n",
        "        unique_values = get_unique_values(data, selected_attribute, target_framework)\n",
        "        new_used_attributes = used_attributes.copy()\n",
        "        new_used_attributes.add(selected_attribute)\n",
        "\n",
        "        for value in unique_values:\n",
        "            mask = create_mask(data, selected_attribute, value, target_framework)\n",
        "\n",
        "            if target_framework == 'pytorch':\n",
        "                if isinstance(data, torch.Tensor):\n",
        "                    subset_data = data[mask]\n",
        "                else:\n",
        "                    tensor_data = torch.tensor(data, dtype=torch.float32)\n",
        "                    subset_data = tensor_data[mask]\n",
        "            else:  # sklearn/numpy\n",
        "                if isinstance(data, np.ndarray):\n",
        "                    subset_data = data[mask]\n",
        "                else:\n",
        "                    subset_data = data.numpy()[mask]\n",
        "\n",
        "            value_int = int(get_item_value(value, target_framework))\n",
        "\n",
        "            # Handle empty subset - assign majority class from current node\n",
        "            if len(subset_data) == 0:\n",
        "                unique_vals, counts = get_unique_with_counts(data, -1, target_framework)\n",
        "                if target_framework == 'pytorch':\n",
        "                    majority_idx = torch.argmax(counts)\n",
        "                    majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "                else:\n",
        "                    majority_idx = np.argmax(counts)\n",
        "                    majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "\n",
        "                if print_construction:\n",
        "                    print_node_info(f\"Branch {cols[selected_attribute]} = {value_int} (empty subset)\", level)\n",
        "                tree_node['branches'][value_int] = majority_class\n",
        "                continue\n",
        "\n",
        "            if print_construction:\n",
        "                print_node_info(f\"Branch {cols[selected_attribute]} = {value_int}\", level)\n",
        "\n",
        "            # RECURSIVE CALL - STORE THE RESULT!\n",
        "            subtree = construct_tree(\n",
        "                subset_data,\n",
        "                cols,\n",
        "                new_used_attributes,\n",
        "                level + 1,\n",
        "                max_depth,\n",
        "                target_framework,\n",
        "                print_construction\n",
        "            )\n",
        "\n",
        "            tree_node['branches'][value_int] = subtree\n",
        "\n",
        "        return tree_node\n",
        "\n",
        "    except Exception as e:\n",
        "        if print_construction:\n",
        "            print_node_info(f\"Error in tree construction: {e}\", level)\n",
        "        # Return majority class as fallback\n",
        "        try:\n",
        "            unique_vals, counts = get_unique_with_counts(data, -1, target_framework)\n",
        "            if target_framework == 'pytorch':\n",
        "                majority_idx = torch.argmax(counts)\n",
        "                majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "            else:\n",
        "                majority_idx = np.argmax(counts)\n",
        "                majority_class = int(get_item_value(unique_vals[majority_idx], target_framework))\n",
        "            return majority_class\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "def predict_single_sample(tree, sample, cols):\n",
        "    \"\"\"\n",
        "    Predict class for a single sample using the constructed tree\n",
        "\n",
        "    Args:\n",
        "        tree: The constructed decision tree (dict or int)\n",
        "        sample: Single data sample (list or array)\n",
        "        cols: Column names\n",
        "\n",
        "    Returns:\n",
        "        Predicted class (int) or None if prediction fails\n",
        "    \"\"\"\n",
        "    if isinstance(tree, int):\n",
        "        return tree\n",
        "\n",
        "    if not isinstance(tree, dict) or 'attribute' not in tree:\n",
        "        return None\n",
        "\n",
        "    attribute_idx = tree['attribute']\n",
        "\n",
        "    if attribute_idx >= len(sample):\n",
        "        return None\n",
        "\n",
        "    attribute_value = int(sample[attribute_idx])\n",
        "\n",
        "    if attribute_value not in tree['branches']:\n",
        "        return None\n",
        "\n",
        "    subtree = tree['branches'][attribute_value]\n",
        "\n",
        "    return predict_single_sample(subtree, sample, cols)\n",
        "\n",
        "def predict_batch(tree, data, cols):\n",
        "    \"\"\"\n",
        "    Predict classes for multiple samples\n",
        "\n",
        "    Args:\n",
        "        tree: The constructed decision tree\n",
        "        data: Array of samples (each row is a sample)\n",
        "        cols: Column names\n",
        "\n",
        "    Returns:\n",
        "        List of predicted classes\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    for sample in data:\n",
        "        pred = predict_single_sample(tree, sample, cols)\n",
        "        predictions.append(pred)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def print_tree_structure(tree, cols, level=0, prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Pretty print the tree structure\n",
        "\n",
        "    Args:\n",
        "        tree: The constructed decision tree\n",
        "        cols: Column names\n",
        "        level: Current depth level\n",
        "        prefix: String prefix for indentation\n",
        "    \"\"\"\n",
        "    if isinstance(tree, int):\n",
        "        print(f\"{prefix}├── Class {tree}\")\n",
        "        return\n",
        "\n",
        "    if not isinstance(tree, dict) or 'attribute' not in tree:\n",
        "        print(f\"{prefix}├── None\")\n",
        "        return\n",
        "\n",
        "    attr_name = tree['attribute_name']\n",
        "    gain = tree.get('gain', 0)\n",
        "\n",
        "    if level == 0:\n",
        "        print(f\"Root [{attr_name}] (gain: {gain:.4f})\")\n",
        "\n",
        "    branches = tree['branches']\n",
        "    branch_items = list(branches.items())\n",
        "\n",
        "    for i, (value, subtree) in enumerate(branch_items):\n",
        "        is_last = (i == len(branch_items) - 1)\n",
        "\n",
        "        if level == 0:\n",
        "            print(f\"├── = {value}:\")\n",
        "            new_prefix = \"│   \"\n",
        "        else:\n",
        "            branch_symbol = \"└──\" if is_last else \"├──\"\n",
        "            print(f\"{prefix}{branch_symbol} = {value}:\")\n",
        "            new_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
        "\n",
        "        if isinstance(subtree, int):\n",
        "            print(f\"{new_prefix}├── Class {subtree}\")\n",
        "        elif isinstance(subtree, dict):\n",
        "            attr_name = subtree['attribute_name']\n",
        "            gain = subtree.get('gain', 0)\n",
        "            print(f\"{new_prefix}├── [{attr_name}] (gain: {gain:.4f})\")\n",
        "            print_tree_structure(subtree, cols, level + 1, new_prefix)\n",
        "        else:\n",
        "            print(f\"{new_prefix}├── None\")\n",
        "\n",
        "def print_node_info(message, level):\n",
        "    \"\"\"Print formatted node information with proper indentation\"\"\"\n",
        "    indent = \"|  \" * level\n",
        "    print(f\"Level {level}: Node Info - {indent}{message}\")\n",
        "\n",
        "def test_single_dataset(dataset_info):\n",
        "    \"\"\"Test a single dataset and return results\"\"\"\n",
        "    dataset_name = dataset_info[\"name\"]\n",
        "    data_path = dataset_info[\"path\"]\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\" TESTING DATASET: {dataset_name.upper()}\")\n",
        "    print(f\" File: {data_path}\")\n",
        "    print(f\" Framework: {framework.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(data_path)\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading dataset {data_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(f\" Target column: '{df.columns[-1]}' (last column)\")\n",
        "\n",
        "    df_processed, label_encoders = preprocess_data(df)\n",
        "\n",
        "    if framework == 'pytorch':\n",
        "        dataset = torch.tensor(df_processed.values, dtype=torch.float32)\n",
        "    else:\n",
        "        dataset = df_processed.values.astype(np.float32)\n",
        "\n",
        "    cols = list(df_processed.columns)\n",
        "\n",
        "    print(f\"\\n DATASET SUMMARY\")\n",
        "    print(f\"{'='*40}\")\n",
        "    print(f\"Processed dataset shape: {dataset.shape}\")\n",
        "    print(f\"Number of features: {len(cols) - 1}\")\n",
        "    print(f\"Features: {cols[:-1][:3]}{'...' if len(cols) > 4 else ''}\")\n",
        "    print(f\"Target: {cols[-1]}\")\n",
        "    print(f\"Framework: {framework.upper()}\")\n",
        "    print(f\"Data type: {type(dataset)}\")\n",
        "\n",
        "    # Get unique classes in target column\n",
        "    if framework == 'pytorch':\n",
        "        unique_classes, class_counts = torch.unique(dataset[:, -1], return_counts=True)\n",
        "        unique_classes = unique_classes.int().tolist()\n",
        "        class_counts = class_counts.tolist()\n",
        "    else:\n",
        "        unique_classes, class_counts = np.unique(dataset[:, -1], return_counts=True)\n",
        "        unique_classes = unique_classes.astype(int).tolist()\n",
        "        class_counts = class_counts.tolist()\n",
        "\n",
        "    print(f\"Number of classes: {len(unique_classes)}\")\n",
        "    print(f\"Class distribution: {dict(zip(unique_classes, class_counts))}\")\n",
        "\n",
        "    try:\n",
        "        print(f\"\\n DECISION TREE CONSTRUCTION\")\n",
        "        print(f\"{'='*40}\")\n",
        "\n",
        "        total_samples = len(dataset)\n",
        "        train_split = 0.8\n",
        "        train_size = int(total_samples * train_split)\n",
        "\n",
        "        print(f\"Total samples: {total_samples}\")\n",
        "        print(f\"Training samples: {train_size}\")\n",
        "        print(f\"Testing samples: {total_samples - train_size}\")\n",
        "\n",
        "        # Split data\n",
        "        if framework == 'pytorch':\n",
        "            torch.manual_seed(42)\n",
        "            indices = torch.randperm(total_samples)\n",
        "            dataset_shuffled = dataset[indices]\n",
        "\n",
        "            train_data = dataset_shuffled[:train_size]\n",
        "            test_data = dataset_shuffled[train_size:]\n",
        "        else:\n",
        "            np.random.seed(42)\n",
        "            indices = np.random.permutation(total_samples)\n",
        "            dataset_shuffled = dataset[indices]\n",
        "\n",
        "            train_data = dataset_shuffled[:train_size]\n",
        "            test_data = dataset_shuffled[train_size:]\n",
        "\n",
        "        print(f\"\\n Constructing decision tree using training data...\")\n",
        "\n",
        "        # Adjust max depth based on dataset size and complexity\n",
        "        if len(cols) > 15:  # Complex datasets like mushrooms\n",
        "            max_depth = 7\n",
        "        elif len(cols) > 10:  # Medium datasets\n",
        "            max_depth = 6\n",
        "        else:  # Simple datasets\n",
        "            max_depth = 5\n",
        "\n",
        "        tree = construct_tree(\n",
        "            train_data,\n",
        "            cols=cols,\n",
        "            target_framework=framework,\n",
        "            max_depth=max_depth,\n",
        "            print_construction=print_construction_flag\n",
        "        )\n",
        "\n",
        "        if tree is not None:\n",
        "            print(f\"\\n Decision tree construction completed!\")\n",
        "\n",
        "            if print_tree_flag:\n",
        "                print(f\"\\n DECISION TREE STRUCTURE\")\n",
        "                print(\"=\"*60)\n",
        "                print_tree_structure(tree, cols)\n",
        "                print()\n",
        "\n",
        "            # Prepare test data\n",
        "            if framework == 'pytorch':\n",
        "                X_test = test_data[:, :-1]\n",
        "                y_test = test_data[:, -1]\n",
        "            else:  # sklearn/numpy\n",
        "                X_test = test_data[:, :-1]\n",
        "                y_test = test_data[:, -1]\n",
        "\n",
        "            # Get class names for better reporting\n",
        "            target_col = cols[-1]\n",
        "            if target_col in label_encoders:\n",
        "                le = label_encoders[target_col]\n",
        "                class_names = {i: le.inverse_transform([i])[0] for i in range(len(le.classes_))}\n",
        "            else:\n",
        "                class_names = None\n",
        "\n",
        "            # Evaluate the tree\n",
        "            evaluation_results = evaluate_decision_tree(tree, X_test, y_test, cols, class_names)\n",
        "\n",
        "            return {\n",
        "                'dataset_name': dataset_name,\n",
        "                'success': True,\n",
        "                'results': evaluation_results,\n",
        "                'dataset_info': {\n",
        "                    'shape': df.shape,\n",
        "                    'num_features': len(cols) - 1,\n",
        "                    'num_classes': len(unique_classes),\n",
        "                    'class_distribution': dict(zip(unique_classes, class_counts))\n",
        "                }\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            print(\" Failed to construct decision tree!\")\n",
        "            return {\n",
        "                'dataset_name': dataset_name,\n",
        "                'success': False,\n",
        "                'error': 'Tree construction failed'\n",
        "            }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error in decision tree construction and evaluation: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return {\n",
        "            'dataset_name': dataset_name,\n",
        "            'success': False,\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "def print_summary_report(all_results):\n",
        "    \"\"\"Print a comprehensive summary of results across all datasets\"\"\"\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\" COMPREHENSIVE SUMMARY REPORT - {framework.upper()} FRAMEWORK\")\n",
        "    print(f\"{'='*100}\")\n",
        "\n",
        "    successful_results = [r for r in all_results if r['success']]\n",
        "    failed_results = [r for r in all_results if not r['success']]\n",
        "\n",
        "    if successful_results:\n",
        "        print(f\"\\n SUCCESSFUL EVALUATIONS: {len(successful_results)}/{len(all_results)}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Summary table\n",
        "        print(f\"{'Dataset':<15} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Tree Depth':<12} {'Nodes':<8}\")\n",
        "        print(f\"{'-'*80}\")\n",
        "\n",
        "        for result in successful_results:\n",
        "            name = result['dataset_name']\n",
        "            metrics = result['results']\n",
        "            accuracy = metrics['accuracy']\n",
        "            precision = metrics['precision_weighted']\n",
        "            recall = metrics['recall_weighted']\n",
        "            f1 = metrics['f1_weighted']\n",
        "            depth = metrics['tree_complexity']['max_depth']\n",
        "            nodes = metrics['tree_complexity']['num_nodes']\n",
        "\n",
        "            print(f\"{name:<15} {accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {depth:<12} {nodes:<8}\")\n",
        "\n",
        "        # Best performer\n",
        "        best_accuracy = max(successful_results, key=lambda x: x['results']['accuracy'])\n",
        "        print(f\"\\n BEST PERFORMER (Accuracy): {best_accuracy['dataset_name']} ({best_accuracy['results']['accuracy']:.4f})\")\n",
        "\n",
        "        # Dataset complexity analysis\n",
        "        print(f\"\\n DATASET COMPLEXITY ANALYSIS\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        for result in successful_results:\n",
        "            info = result['dataset_info']\n",
        "            tree_stats = result['results']['tree_complexity']\n",
        "\n",
        "            print(f\"\\n{result['dataset_name']}:\")\n",
        "            print(f\"  • Dataset size: {info['shape'][0]:,} samples, {info['num_features']} features\")\n",
        "            print(f\"  • Classes: {info['num_classes']} ({list(info['class_distribution'].keys())})\")\n",
        "            print(f\"  • Tree complexity: {tree_stats['max_depth']} depth, {tree_stats['num_nodes']} nodes\")\n",
        "            print(f\"  • Performance: {result['results']['accuracy']:.1%} accuracy\")\n",
        "\n",
        "    if failed_results:\n",
        "        print(f\"\\n FAILED EVALUATIONS: {len(failed_results)}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        for result in failed_results:\n",
        "            print(f\"  • {result['dataset_name']}: {result.get('error', 'Unknown error')}\")\n",
        "\n",
        "    print(f\"\\n{'='*100}\")\n",
        "\n",
        "def test_all_datasets():\n",
        "    \"\"\"Test all datasets and provide comprehensive results\"\"\"\n",
        "    print(f\"STARTING MULTI-DATASET EVALUATION\")\n",
        "    print(f\"Framework: {framework.upper()}\")\n",
        "    print(f\"Datasets to test: {len(datasets)}\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for i, dataset_info in enumerate(datasets, 1):\n",
        "        print(f\"\\n Processing dataset {i}/{len(datasets)}: {dataset_info['name']}\")\n",
        "        result = test_single_dataset(dataset_info)\n",
        "        if result:\n",
        "            all_results.append(result)\n",
        "\n",
        "    # Print comprehensive summary\n",
        "    print_summary_report(all_results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test all datasets\n",
        "    results = test_all_datasets()\n",
        "\n",
        "    print(f\"\\n EVALUATION COMPLETE!\")\n",
        "    print(f\"Framework used: {framework.upper()}\")\n",
        "    print(f\"Total datasets processed: {len(results)}\")\n",
        "    print(f\"Successful evaluations: {len([r for r in results if r['success']])}\")\n",
        "\n",
        "    # Optional: Save results to file\n",
        "    # import json\n",
        "    # with open(f'results_{framework}.json', 'w') as f:\n",
        "    #     json.dump(results, f, indent=2)"
      ]
    }
  ]
}